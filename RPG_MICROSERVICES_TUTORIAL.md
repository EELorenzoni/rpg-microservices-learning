# üßô‚Äç‚ôÇÔ∏è RPG Microservices: From Prompt to Production
> **A Prompt-Driven Engineering Course**

Este documento es un tutorial maestro dise√±ado para ser consumido tanto por humanos como por Agentes de IA. Su objetivo es guiar la construcci√≥n de un sistema de RPG distribuido usando Go, Kafka y Event-Driven Architecture.

---

## üìÇ Fase 0: El "Prime" (Configuraci√≥n del Agente)

Esta fase no escribe c√≥digo, sino comportamiento. Antes de empezar, copia y pega el siguiente prompt en tu chat con la IA. Esto configurar√° su "sys-call" mental y su rol como experto.

### ü§ñ El Prompt Maestro del Sistema

Copiar el siguiente bloque y enviarlo a la IA para iniciar la sesi√≥n:

```markdown
ACT√öA COMO UN "ARQUITECTO SENIOR EN GO E INGENIERO DE PLATFORM ENGINEERING".

## TU OBJETIVO
Guiar al usuario en la construcci√≥n de un Backend RPG Distribuido usando Go, Apache Kafka y Event-Driven Architecture. Estamos haciendo "Desarrollo Guiado por Prompts": no solo escribir√°s c√≥digo, sino que explicar√°s los *prompts* necesarios para generar ese c√≥digo en el futuro o en otros agentes.

## RESTRICCIONES T√âCNICAS
1.  **Lenguaje:** Go 1.22+ (Tipado estricto, features modernas).
2.  **Arquitectura:** Hexagonal / Clean Architecture.
    - `cmd/`: Puntos de entrada.
    - `internal/core/domain`: L√≥gica y Modelos (Go Puro).
    - `internal/core/ports`: Interfaces (Repository, EventBus).
    - `internal/core/services`: Casos de uso (Vertical Slicing).
    - `internal/adapters`: Implementaciones concretas.
3.  **Comunicaci√≥n:**
    - S√≠ncrona: REST API (net/http est√°ndar).
    - As√≠ncrona: Kafka (usando `github.com/segmentio/kafka-go`).
4.  **Platform Engineering:**
    - Kafka centralizado en proyecto separado
    - Admin API para gesti√≥n de topics
    - Configuraci√≥n por variables de entorno (.env)
5.  **Event-Driven:**
    - Todos los eventos con estructura est√°ndar: `event_type`, `occurred_at`, `data`
    - Publicar eventos de √©xito Y fallo
    - Dead Letter Queue (DLQ) para resiliencia

## REGLAS DE COMPORTAMIENTO
1.  **Piensa Primero:** Antes de codear, define la estructura de archivos o el flujo l√≥gico.
2.  **Event-First:** Define eventos de dominio antes de escribir handlers.
3.  **Educativo:** Explica *por qu√©* elegiste un patr√≥n (ej. "¬øPor qu√© usar DLQ?").
4.  **Iterativo:** Comienza con el MVP, luego refactoriza.
5.  **Idioma:** Todas tus explicaciones y comentarios deben ser en Espa√±ol Latinoamericano.
6.  **SOLID es obligatorio:** Aplicar los 5 principios en todo el c√≥digo.

## CONTEXTO ACTUAL
Estamos empezando desde cero. Espera instrucciones para la Fase 1.
```

---

## üìÇ Fase 1: Platform Engineering - Kafka Centralizado

### 1.1 Creaci√≥n del Proyecto Platform

**Prompt para Platform Admin:**

```markdown
TAREA: Crear Platform Kafka Admin

Crea un proyecto Go independiente llamado `platform-kafka-admin` que centralice la gesti√≥n de Kafka.

Estructura:
/cmd/admin-api/main.go     ‚Üí API REST para gestionar topics
/internal/core/service.go  ‚Üí L√≥gica de admin (CreateTopic, ListTopics, DeleteTopic)
/internal/handlers/http.go ‚Üí Handlers HTTP (Gin)
/docker-compose.yml        ‚Üí Kafka + Kafka UI
/.env                      ‚Üí Variables de entorno
/Makefile                  ‚Üí Automatizaci√≥n

Requisitos:
1. Kafka en modo KRaft (sin Zookeeper)
2. Admin API en puerto 3000
3. Endpoints:
   - POST /topics (crear topic)
   - GET /topics (listar topics)
   - DELETE /topics/:name (eliminar topic)
4. Configuraci√≥n estricta por .env (si env var no existe, fallar)
5. Kafka UI en puerto 8080

Configuraci√≥n de Kafka para desarrollo:
- KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
- KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
```

### 1.2 Configuraci√≥n Profesional

**Prompt para Variables de Entorno:**

```markdown
TAREA: Implementar configuraci√≥n con godotenv

Requisitos:
1. Instalar `github.com/joho/godotenv`
2. Leer archivo .env al inicio de main.go
3. Validar que existan las variables requeridas:
   - KAFKA_BROKER (direcci√≥n del broker)
   - ADMIN_PORT (puerto de la API)
4. Si alguna variable est√° vac√≠a, fallar con log.Fatal explicativo
5. NO usar valores por defecto hardcodeados

Archivo .env debe contener:
KAFKA_BROKER=127.0.0.1:9094
ADMIN_PORT=:3000
```

---

## üìÇ Fase 2: Hero Service - CRUD Event-Driven

### 2.1 Estructura Hexagonal

**Prompt para Estructura del Proyecto:**

```markdown
TAREA: Crear proyecto Hero Service (section-05-full-cycle)

Estructura Hexagonal completa:
/cmd/api/main.go              ‚Üí HTTP Server
/cmd/consumer/main.go         ‚Üí Kafka Consumer
/internal/core
    /domain/hero.go           ‚Üí Entidad Hero + Factory
    /ports/repositories.go    ‚Üí Interface HeroRepository
    /ports/events.go          ‚Üí Interface EventBus
    /services/herosrv
        /service.go           ‚Üí Struct + Dependencies
        /create.go            ‚Üí Command: Create
        /get.go               ‚Üí Query: Get
        /update.go            ‚Üí Command: Update
        /delete.go            ‚Üí Command: Delete
        /list.go              ‚Üí Query: List
/internal/handlers/herohdl
    /http.go                  ‚Üí REST Handlers
    /consumer.go              ‚Üí Kafka Consumer Handler
/internal/repositories/herorepo
    /memory.go                ‚Üí In-Memory Repository
    /kafka_repo.go            ‚Üí Kafka EventBus Implementation

Reglas:
1. Vertical Slicing: Cada operaci√≥n CRUD en archivo separado
2. CQS: Separar Commands (escribir) de Queries (leer)
3. Dependency Injection: Service recibe interfaces, no implementaciones
```

### 2.2 Domain Layer (Entidad Hero)

**Prompt para Domain:**

```markdown
TAREA: Implementar Entidad Hero con validaciones

Crear domain/hero.go con:

type Hero struct {
    ID        string
    Name      string
    Level     int
    Power     int
    CreatedAt time.Time
}

Reglas:
1. Factory Pattern: NewHero(id, name) que valide:
   - Name no puede estar vac√≠o
   - ID debe ser v√°lido
2. Retornar puntero (*Hero)
3. Errors de dominio predefinidos:
   - ErrHeroNameEmpty
4. Poder inicial: 10, Level inicial: 1
```

### 2.3 Generaci√≥n Autom√°tica de IDs

**Prompt para UUID:**

```markdown
TAREA: Implementar generaci√≥n autom√°tica de IDs

Requisitos:
1. Instalar `github.com/google/uuid`
2. En herosrv/create.go:
   - NO recibir ID en CreateHeroCommand
   - Generar ID con uuid.New().String()
   - Retornar el h√©roe creado (*domain.Hero, error)
3. En HTTP Handler:
   - Request JSON sin campo "id"
   - Response debe incluir el h√©roe completo con su ID generado

Ejemplo Response:
{
  "status": "created",
  "hero": {
    "id": "a1b2c3d4-...",
    "name": "Arthas",
    ...
  }
}
```

### 2.4 Event-Driven Architecture

**Prompt para Eventos:**

```markdown
TAREA: Implementar publicaci√≥n de eventos con estructura est√°ndar

Estructura de eventos:
{
  "event_type": "HeroCreated",
  "occurred_at": "2025-12-18T16:00:00Z",
  "data": {
    "id": "...",
    "name": "...",
    ...
  }
}

Tipos de eventos:
‚úÖ √âxito:
- HeroCreated
- HeroUpdated
- HeroDeleted

‚ùå Fallo:
- HeroCreateFailed
- HeroUpdateFailed
- HeroDeleteFailed

Reglas:
1. SIEMPRE publicar eventos (tanto √©xito como fallo)
2. En caso de error de validaci√≥n, publicar evento de fallo ANTES de retornar error
3. En caso de √©xito, publicar evento DESPU√âS de persistir en DB
4. Logs claros: "‚úÖ Hero guardado en DB" ‚Üí "üì® Evento 'HeroCreated' publicado correctamente"
```

### 2.5 Dead Letter Queue (DLQ)

**Prompt para Consumer Robusto:**

```markdown
TAREA: Implementar Consumer con DLQ

Crear internal/handlers/herohdl/consumer.go con:

1. DLQ Writer: Productor a topic "hero-events-05-dlq"
2. FetchMessage (NO ReadMessage) para control manual de commits
3. Funci√≥n processMessage(msg kafka.Message) error que:
   - Retorne error si payload es inv√°lido
4. L√≥gica de manejo:
   - Si processMessage falla ‚Üí Enviar mensaje a DLQ con headers:
     * "original-topic"
     * "error-reason"
   - Hacer commit SIEMPRE (para avanzar, no bloquear)

Simulaci√≥n de poison message:
Si payload == `{"fail":true}`, retornar error para probar DLQ
```

---

## üìÇ Fase 3: Routing Inteligente (REST)

**Prompt para Router:**

```markdown
TAREA: Implementar routing RESTful inteligente

En cmd/api/main.go, crear l√≥gica de routing:

Endpoint: /heroes

L√≥gica:
- Si query param "id" est√° presente:
  ‚Üí Operaciones sobre UN h√©roe
  - GET    ‚Üí GetHero
  - PUT    ‚Üí UpdateHero
  - DELETE ‚Üí DeleteHero

- Si query param "id" NO est√° presente:
  ‚Üí Operaciones sobre la COLECCI√ìN
  - POST ‚Üí CreateHero
  - GET  ‚Üí ListHeroes

Ejemplo:
POST /heroes {"name":"Arthas"}           ‚Üí CreateHero
GET /heroes                              ‚Üí ListHeroes
GET /heroes?id=abc-123                   ‚Üí GetHero
PUT /heroes?id=abc-123 {"name":"Updated"} ‚Üí UpdateHero
DELETE /heroes?id=abc-123                ‚Üí DeleteHero
```

---

## üìÇ Fase 4: Tutoriales Avanzados

### 4.1 Gu√≠a de Producci√≥n

**Prompt para Tutorial 07:**

```markdown
TAREA: Crear tutorial "Kafka en Producci√≥n"

Documento: 07-kafka-production-guide.md

Secciones:
1. Par√°metros exhaustivos de topics:
   - min.insync.replicas
   - retention.ms
   - cleanup.policy (delete vs compact)
   - compression.type
2. Viaje de un evento (Producer ‚Üí Broker ‚Üí Consumer)
   - Diagrama de secuencia Mermaid
3. Consumer Groups explicados
   - Rebalanceo
   - Asignaci√≥n de particiones
4. Sem√°ntica de entrega:
   - At-least-once
   - At-most-once
   - Exactly-once (con limitaciones reales)
5. Estrategias de error (DLQ, Retries)
6. Checklist de producci√≥n

Tono: Ingeniero Senior, sin marketing, con experiencia real operando Kafka.
```

### 4.2 An√°lisis de Flujo de Mensajes

**Prompt para Tutorial 08:**

```markdown
TAREA: Crear tutorial "Flujo del Mensaje Real"

Documento: 08-kafka-event-flow.md

Explicar usando el evento HeroCreated:
1. Anatom√≠a de un mensaje Kafka:
   - Topic, Key, Value, Headers, Partition, Offset
2. Por qu√© la Key importa (ordenamiento, hot partitions)
3. Responsabilidad del Consumer:
   - Idempotencia (UPSERT, no INSERT)
   - Manejo de duplicados
4. Ejemplo JSON real del evento

Incluir advertencias:
- Orden solo existe DENTRO de una partici√≥n
- Duplicados son inevitables (network failures)
- Consumer debe ser idempotente
```

---

## üìÇ Fase 5: Documentaci√≥n Completa

**Prompt para Tutorial 05:**

```markdown
TAREA: Crear tutorial completo "Ciclo Completo y SOLID"

Documento: 05-ciclo-completo-solid.md

Contenidos:
1. Diagrama de secuencia Mermaid (dark theme):
   - Flujo Create con √©xito
   - Flujo Create con fallo
   - Consumer con DLQ
2. Estructura del proyecto (Vertical Slicing)
3. Tabla SOLID con ejemplos concretos del c√≥digo
4. Secci√≥n de pruebas con comandos curl:
   - Crear h√©roe (sin ID)
   - Listar h√©roes
   - Consultar uno
   - Actualizar
   - Eliminar
   - Probar fallo (name vac√≠o)
   - Ver DLQ en acci√≥n
5. Logs esperados del Consumer

Nota: IDs se generan autom√°ticamente, no se env√≠an en requests
```

---

## üìÇ Fase 6: Pr√≥ximos Pasos (Battle System)

**Prompt para Sistema de Combate:**

```markdown
TAREA: Dise√±ar Sistema de Combate As√≠ncrono

Pr√≥ximo servicio: Battle Service

API:
POST /battles
{
  "attacker_id": "uuid",
  "defender_id": "uuid"
}

Flujo:
1. API valida que ambos h√©roes existan
2. Publica evento "BattleStarted"
3. Consumer calcula:
   - Da√±o = Attacker.Power + Random(1-10) - Defender.Level
   - Actualiza Defender.HP
4. Publica "HeroAttacked" con resultado
5. Si Defender.HP <= 0, publica "HeroDefeated"

Eventos:
- BattleStarted
- HeroAttacked (con da√±o)
- BattleEnded (ganador)

Retos:
- Concurrent battles del mismo h√©roe
- Optimistic locking en DB
- Registro de historial de batallas
```

---

## ‚úÖ ¬°Misi√≥n Cumplida!

Si has seguido los prompts fase por fase, ahora tienes:
- ‚úÖ Platform Engineering (Kafka centralizado)
- ‚úÖ Hero Service (CRUD completo + eventos)
- ‚úÖ Event-Driven Architecture
- ‚úÖ Dead Letter Queue
- ‚úÖ Documentaci√≥n profesional
- ‚úÖ Arquitectura Hexagonal + SOLID

**Pr√≥ximo nivel:**
- [ ] Battle System
- [ ] PostgreSQL (migrations, queries)
- [ ] Tests (unit + integration)
- [ ] Observabilidad (slog, metrics, tracing)
