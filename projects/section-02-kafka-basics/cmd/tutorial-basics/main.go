package main

import (
	// "context" es vital en Go para controlar tiempos de espera (timeouts)
	// y cancelaciones de tareas largas. Kafka-go lo usa intensivamente.
	"context"

	// "fmt" se usa para imprimir texto en la consola (stdout).
	"fmt"

	// "log" es similar a fmt, pero agrega fecha/hora y permite salir del programa
	// en caso de errores fatales (log.Fatal).
	"log"

	// "os" nos da acceso al sistema operativo, por ejemplo, para leer
	// los argumentos que escribes en la terminal (ej: 'produce' o 'consume').
	"os"

	// "time" nos sirve para pausar la ejecuci√≥n (Sleep) y manejar duraciones.
	"time"

	// Importamos la librer√≠a externa de Kafka.
	// Aseg√∫rate de correr 'go get github.com/segmentio/kafka-go' antes.
	"github.com/segmentio/kafka-go"
)

// --- CONFIGURACI√ìN ---
// Definimos constantes para no repetir textos y facilitar cambios.
// En un entorno real, esto vendr√≠a de variables de entorno (.env).
const (
	topic         = "rpg-battles"    // El nombre del "chat" o canal donde van los datos.
	brokerAddress = "localhost:9094" // Direcci√≥n del servidor Kafka (Broker).
)

func main() {
	// Verificamos si el usuario ingres√≥ alg√∫n comando.
	// os.Args[0] es el nombre del archivo, os.Args[1] es el primer argumento.
	if len(os.Args) < 2 {
		fmt.Println("Uso correcto: go run main.go [produce|consume]")
		os.Exit(1) // Salimos con c√≥digo de error 1.
	}

	// Capturamos el modo que el usuario quiere ejecutar.
	mode := os.Args[1]

	switch mode {
	case "produce":
		produceMessages() // Ejecuta la funci√≥n de enviar datos.
	case "consume":
		consumeMessages() // Ejecuta la funci√≥n de leer datos.
	default:
		// Si escriben algo que no entendemos, avisamos y salimos.
		fmt.Printf("Modo desconocido: %s. Usa 'produce' o 'consume'\n", mode)
		os.Exit(1)
	}
}

// --- PRODUCTOR (El que env√≠a los mensajes) ---
func produceMessages() {
	// Paso opcional pero recomendado: Asegurar que el topic exista antes de escribir.
	ensureTopic()

	// 1. CONFIGURACI√ìN DEL WRITER (ESCRITOR)
	// El Writer es un componente de alto nivel que gestiona conexiones, reintentos
	// y balanceo de carga autom√°ticamente.
	w := &kafka.Writer{
		Addr:  kafka.TCP(brokerAddress), // A qu√© servidor conectarse.
		Topic: topic,                    // A qu√© t√≥pico escribir.
		// Balancer: Decide a qu√© partici√≥n enviar el mensaje.
		// LeastBytes intenta enviar el mensaje a la partici√≥n que tenga menos datos,
		// ayudando a distribuir la carga equitativamente.
		Balancer: &kafka.LeastBytes{},
	}

	// 'defer' asegura que w.Close() se ejecute justo antes de que la funci√≥n termine.
	// Es vital para cerrar conexiones de red y liberar memoria.
	defer w.Close()

	fmt.Println("‚öîÔ∏è  Iniciando Productor de Batallas...")

	// Simulamos el env√≠o de 5 eventos.
	for i := 1; i <= 5; i++ {
		// Creamos el contenido del mensaje (payload).
		msgValue := fmt.Sprintf("Heroe ataca a Orco #%d con 50 de da√±o", i)

		// 2. ESCRIBIR EL MENSAJE
		// WriteMessages env√≠a uno o m√°s mensajes al broker.
		// context.Background() indica que no hay un tiempo l√≠mite espec√≠fico para esta operaci√≥n.
		err := w.WriteMessages(context.Background(),
			kafka.Message{
				// Key: Kafka usa la llave para decidir el orden y la partici√≥n.
				// Mensajes con la misma Key siempre van a la misma partici√≥n en orden.
				Key: []byte(fmt.Sprintf("Key-%d", i)),

				// Value: Es la informaci√≥n real que queremos transmitir.
				// Kafka solo entiende bytes, por eso convertimos el string a []byte.
				Value: []byte(msgValue),
			},
		)

		// Manejo de errores b√°sico.
		if err != nil {
			log.Fatal("Error fatal enviando mensaje:", err)
		}

		fmt.Printf("Enviado: %s\n", msgValue)

		// Esperamos 1 segundo para no saturar la pantalla y simular eventos en tiempo real.
		time.Sleep(1 * time.Second)
	}

	fmt.Println("‚úÖ Todos los ataques enviados.")
}

// --- CONSUMIDOR (El que lee los mensajes) ---
func consumeMessages() {
	// Tambi√©n nos aseguramos que el topic exista, por si arrancamos el consumidor primero.
	ensureTopic()

	// 1. CONFIGURACI√ìN DEL READER (LECTOR)
	r := kafka.NewReader(kafka.ReaderConfig{
		Brokers: []string{brokerAddress},
		Topic:   topic,

		// GroupID: ESTO ES CRUCIAL.
		// Identifica a este consumidor como parte de un equipo "battle-stats-service".
		// Kafka recuerda qu√© mensajes ya ley√≥ este grupo para no repetirlos si el programa se reinicia.
		GroupID: "battle-stats-service",

		// Optimizaciones de red:
		MinBytes: 10e3, // Esperar a tener 10KB de datos antes de responder (menos tr√°fico).
		MaxBytes: 10e6, // M√°ximo 10MB por paquete.

		// StartOffset: Solo aplica si es un grupo nuevo sin historial.
		// FirstOffset significa "leer desde el mensaje m√°s antiguo disponible".
		StartOffset: kafka.FirstOffset,
	})

	// Cerramos la conexi√≥n al terminar (aunque en un loop infinito, esto ocurre al matar el proceso).
	defer r.Close()

	fmt.Println("üõ°Ô∏è  Iniciando Consumidor de Batallas (Esperando eventos)...")

	// 2. BUCLE INFINITO DE LECTURA
	// Los consumidores suelen estar siempre encendidos escuchando.
	for {
		// ReadMessage es BLOQUEANTE.
		// El c√≥digo se detiene en esta l√≠nea hasta que Kafka tenga un mensaje nuevo.
		m, err := r.ReadMessage(context.Background())

		if err != nil {
			// Si hay error (ej. desconexi√≥n moment√°nea), logueamos y esperamos un poco antes de reintentar.
			fmt.Printf("‚ö†Ô∏è  Error leyendo mensaje: %v\n    --> Reintentando en 1s...\n", err)
			time.Sleep(1 * time.Second)
			continue
		}

		// Imprimimos el mensaje.
		// m.Offset es como el ID secuencial del mensaje dentro de la partici√≥n.
		fmt.Printf("Mensaje recibido: %s (offset %d)\n", string(m.Value), m.Offset)
	}
}

// --- UTILIDAD: CREACI√ìN DE TOPICS ---
// Esta funci√≥n usa una conexi√≥n "cruda" (bajo nivel) para administrar Kafka.
func ensureTopic() {
	// 1. Conexi√≥n inicial a cualquier broker disponible.
	conn, err := kafka.Dial("tcp", brokerAddress)
	if err != nil {
		log.Fatal("Error conectando a Kafka para verificar topic:", err)
	}
	defer conn.Close()

	// 2. Preguntar qui√©n es el "Controller" (el jefe del cl√∫ster).
	// Solo el Controller tiene permiso para crear o borrar t√≥picos.
	controller, err := conn.Controller()
	if err != nil {
		log.Fatal("Error obteniendo controlador:", err)
	}

	// 3. Conectarse directamente al Controller.
	var controllerConn *kafka.Conn
	// Construimos la direcci√≥n del controller usando su Host y Puerto.
	controllerConn, err = kafka.Dial("tcp", fmt.Sprintf("%s:%d", controller.Host, controller.Port))
	if err != nil {
		log.Fatal("Error conectando al controlador:", err)
	}
	defer controllerConn.Close()

	// 4. Definir la configuraci√≥n del t√≥pico.
	topicConfigs := []kafka.TopicConfig{
		{
			Topic:             topic,
			NumPartitions:     1, // 1 Partici√≥n = Sin paralelismo de lectura (orden total garantizado).
			ReplicationFactor: 1, // 1 Copia = Sin redundancia (si el nodo cae, perdemos datos).
		},
	}

	// 5. Intentar crear el t√≥pico.
	err = controllerConn.CreateTopics(topicConfigs...)
	if err != nil {
		// Kafka devuelve error si el topic ya existe. En este ejemplo simple,
		// ignoramos ese error espec√≠fico asumiendo que "si falla, es que ya estaba ah√≠".
		fmt.Printf("Nota: Topic '%s' ya existe o acaba de ser creado.\n", topic)
	}
}
