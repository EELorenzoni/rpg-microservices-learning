# 07 - Kafka en ProducciÃ³n: La GuÃ­a Definitiva de Operaciones

> **Rol:** Principal Platform Engineer.
> **Objetivo:** No darte "tips", sino explicarte cÃ³mo no destruir la producciÃ³n a las 3 AM.

Has creado topics y enviado mensajes. Eso es fÃ¡cil.
Operar Kafka en un entorno donde se mueven millones de dÃ³lares o datos crÃ­ticos es otra historia.
AquÃ­ termina la magia y empieza la ingenierÃ­a.

---

## 1. CreaciÃ³n de Topics: ParÃ¡metros Exhaustivos

Cuando haces `POST /topics`, estÃ¡s definiendo el contrato de rendimiento y durabilidad. Un error aquÃ­ es costoso de corregir.

### ParÃ¡metros CrÃ­ticos (Must Know)

| ParÃ¡metro | QuÃ© controla | Problema que resuelve | RecomendaciÃ³n Prod |
| :--- | :--- | :--- | :--- |
| `name` | Identificador Ãºnico. | OrganizaciÃ³n (Namespacing). | Usa prefijos: `domain.entity.event`. Ej: `billing.invoice.created`. |
| `partitions` | Paralelismo. | Velocidad de consumo. | **3 a 6** para empezar. DifÃ­cil de cambiar sin romper orden. |
| `replication.factor` | Durabilidad. | Â¿CuÃ¡ntos servers pueden morir? | **3**. (Permite que caiga 1 sin detener el cluster, o 2 con riesgo). |
| `min.insync.replicas` | GarantÃ­a de Escritura. | Evita perder datos si el lÃ­der acepta pero no replica. | **2**. Obliga a que al menos 2 copias existan antes de decir "OK". |
| `cleanup.policy` | Ciclo de vida. | Disco lleno vs Historial infinito. | `delete` (logs/eventos) o `compact` (tablas de estado). |

### ParÃ¡metros Avanzados (Fine Tuning)

| ParÃ¡metro | QuÃ© controla | Impacto Operativo |
| :--- | :--- | :--- |
| `retention.ms` | Tiempo de vida. | Si pones `-1` (infinito) sin monitoreo, llenarÃ¡s el disco y tirarÃ¡s el cluster. Default: 7 dÃ­as (`604800000`). |
| `retention.bytes` | TamaÃ±o mÃ¡ximo del topic. | "Guarda mÃ¡ximo 100GB". Ãštil para limitar costos de almacenamiento cloud. |
| `segment.bytes` | TamaÃ±o de archivo de log. | Kafka escribe en archivos (`.log`). Si es muy pequeÃ±o, muchos archivos abiertos. Si es muy grande, difÃ­cil de limpiar. Default: 1GB. |
| `compression.type` | Algoritmo (gzip, snappy, lz4). | CPU vs Ancho de Banda. `producer` (lo que mande el cliente) o `lz4` (balanceado) es lo mejor. |
| `max.message.bytes` | TamaÃ±o mÃ¡ximo de 1 mensaje. | Default 1MB. **Â¡Cuidado!** Si subes esto, debes subirlo en Brokers y Consumers tambiÃ©n o todo fallarÃ¡. |
| `unclean.leader.election.enable` | Disponibilidad vs Consistencia. | Si el lÃ­der muere y solo queda una rÃ©plica desactualizada... Â¿la elegimos? `true` = pierdes datos pero sigues online. `false` (default) = te detienes para proteger datos. |

---

## 2. Viaje de un Evento: De Producer a Consumer

Kafka no es "fuego y olvido". Es un compromiso distribuido.

```mermaid
%%{
  init: {
    'theme': 'dark',
    'themeVariables': {
      'primaryColor': '#1f2937',
      'edgeLabelBackground':'#1f2937',
      'tertiaryColor': '#111827',
      'mainBkg': '#1f2937',
      'nodeBorder': '#8b5cf6',
      'lineColor': '#3b82f6',
      'textColor': '#f3f4f6'
    }
  }
}%%
sequenceDiagram
    participant P as ğŸ¦ Producer
    participant L as ğŸ‘‘ Leader Broker
    participant F as ğŸ‘¥ Follower Broker
    participant C as ğŸ¢ Consumer

    Note over P, F: Fase 1: PublicaciÃ³n (Durabilidad)
    P->>P: Hash(Key) % Partitions -> Elige ParticiÃ³n 0
    P->>L: Produce (Msg)
    L->>L: Escribe en Log (Memoria -> Disco)
    L->>F: ReplicaciÃ³n Async
    F-->>L: ACK (Ya lo tengo)
    
    Note right of L: min.insync.replicas=2 ?<br/>Si F responde, procedemos.
    
    L-->>P: ACK (Offset 1050 confirmada)

    Note over L, C: Fase 2: Consumo (Procesamiento)
    C->>L: Fetch (Dame desde Offset 1050)
    L-->>C: Msg [1050, 1051, 1052]
    
    loop Procesamiento
        C->>C: LÃ³gica de Negocio (Save DB, Email, etc)
    end
    
    C->>L: Commit Offset 1053 (Ya terminÃ©)
```

### Verdades IncÃ³modas
1.  **ACKs**: Si configuras `acks=0` (Producer), Kafka no te promete nada. Si `acks=all`, esperarÃ¡ a las rÃ©plicas (`min.insync.replicas`). **Usa `acks=all` en producciÃ³n**.
2.  **Orden**: Solo existe DENTRO de una particiÃ³n. Entre particiones no hay orden global.
3.  **Duplicados**: Si el Producer envÃ­a, el Broker guarda, pero el ACK de vuelta falla (red), el Producer reintentarÃ¡. **Resultado: Mensaje duplicado en Kafka**. Tu consumidor debe ser **Idempotente**.

---

## 3. Consumers y Consumer Groups (Sin Mitos)

Esta es la fuente #1 de confusiÃ³n.

### Â¿Un topic puede tener mÃºltiples consumers?
**SÃ**.
- Si tienen **diferente `GroupID`**: Es **Fan-Out** (Pub/Sub). Todos reciben copia de todo. (Ej: Servicio de FacturaciÃ³n y Servicio de Analytics escuchando `ventas`).
- Si tienen **mismo `GroupID`**: Es **Load Balancing** (Queue). Se reparten el trabajo.

### La Magia del Rebalanceo
Imagina un Topic con **4 Particiones** y un Consumer Group "Heroes".

1.  **Levantas Consumer A**: Kafka le asigna [0, 1, 2, 3]. (Trabaja duro).
2.  **Levantas Consumer B**: Kafka detecta al nuevo. Pausa a A ("Stop the world"). Reasigna: A=[0,1], B=[2,3].
3.  **Consumer A muere (OOM)**: Kafka espera `session.timeout.ms`. Declara a A muerto. Reasigna [0,1,2,3] a B.

**Peligro**: Si tu procesamiento tarda mÃ¡s que `max.poll.interval.ms`, Kafka creerÃ¡ que moriste y te quitarÃ¡ las particiones. Â¡EntrarÃ¡s en un loop de rebalanceos infinitos!

---

## 4. Â¿QuÃ© pasa con un mensaje? (SemÃ¡ntica de Entrega)

### Escenario A: "Happy Path" (At-Least-Once)
1.  Consumer lee mensaje Offset 5.
2.  Procesa ok.
3.  Hace Commit Offset 6.
**Resultado**: Perfecto.

### Escenario B: Consumer muere procesando
1.  Consumer lee mensaje Offset 5.
2.  Procesa a medias (o termina pero muere antes del commit).
3.  Nuevo Consumer toma la particiÃ³n. Kafka le dice "El Ãºltimo commit fue 5".
4.  Nuevo Consumer lee Offset 5 **de nuevo**.
**Resultado**: **Mensaje Duplicado**. Tu cÃ³digo debe manejar esto (Upsert en DB, dedup por ID).

### Escenario C: Auto-Commit prematuro (At-Most-Once - PELIGROSO)
1.  Consumer lee.
2.  Kafka librerÃ­a hace Auto-Commit en background.
3.  Consumer crashea procesando.
**Resultado**: **Mensaje Perdido**. Kafka cree que ya lo procesaste.
**RecomendaciÃ³n**: Desactiva `enable.auto.commit` si tu lÃ³gica es crÃ­tica. Haz commit manual al final.

---

## 5. Manejo de Errores en ProducciÃ³n

Â¿QuÃ© haces si llega un mensaje "malformado" que hace crashear tu consumer?

### âŒ Lo que NO debes hacer
- Poner un `for { retry }` infinito. BloquearÃ¡s toda la particiÃ³n. Nadie mÃ¡s procesarÃ¡ nada detrÃ¡s de ese mensaje.

### âœ… Estrategia Ganadora: Dead Letter Queue (DLQ)
1.  Intenta procesar `try...catch`.
2.  Si falla (y no es transitorio como DB down), **no reintentes infinitamente**.
3.  Publica ese mensaje fallido en otro topic: `hero-events-dlq`.
4.  Haz Commit del original y sigue con el siguiente.
5.  Alerta a un humano para revisar la DLQ.

---

## 6. Checklist Final para ProducciÃ³n

No despliegues a Prod sin responder esto:

1.  [ ] **Retention**: Â¿EstÃ¡ configurada? Â¿Tengo disco para soportar `retention.bytes` si el trÃ¡fico se duplica?
2.  **Particiones**: Â¿Puse suficientes? (Aumentarlas luego rompe la garantÃ­a de llave/orden). Empieza con 3 o 6.
3.  **Clave (Key)**: Â¿Estoy usando una Key con buena cardinalidad (UserID)? Â¿O estoy mandando `null` y perdiendo orden?
4.  **ReplicaciÃ³n**: Â¿Es al menos 3? Â¿`min.insync.replicas` es 2?
5.  **Idempotencia**: Â¿QuÃ© pasa si proceso el mismo JSON dos veces? Â¿Mi DB explota o hace update? (Debe hacer update).
6.  **Alertas**: Â¿Tengo alerta si el "Consumer Lag" (retraso) sube de 1000 mensajes?

---
*Bienvenido a la ingenierÃ­a de sistemas distribuidos. Kafka es una bestia poderosa, trÃ¡tala con respeto.*
