# 05 - Ciclo Completo y Patrones SOLID

Hemos llegado al final de nuestra implementaci√≥n "Core".
En esta secci√≥n conectamos **todos** los puntos y aplicamos el patr√≥n **CQS (Command Query Separation)** con **CRUD completo**.

## 1. El Ciclo de Vida (Full CRUD + Event-Driven)

Nuestro sistema ahora soporta **CRUD completo** con arquitectura event-driven:
1.  **Create**: `POST /heroes` ‚Üí Crea, Persiste y Notifica (`HeroCreated` o `HeroCreateFailed`)
2.  **Read**: `GET /heroes?id=...` ‚Üí Consulta un h√©roe espec√≠fico
3.  **Update**: `PUT /heroes?id=...` ‚Üí Actualiza y Notifica (`HeroUpdated` o `HeroUpdateFailed`)
4.  **Delete**: `DELETE /heroes?id=...` ‚Üí Elimina y Notifica (`HeroDeleted` o `HeroDeleteFailed`)
5.  **List**: `GET /heroes` ‚Üí Lista todos los h√©roes

### Eventos Publicados en Kafka

**Todos** los eventos se publican en `hero-events-05` con estructura est√°ndar:
```json
{
  "event_type": "HeroCreated",
  "occurred_at": "2025-12-18T16:00:00Z",
  "data": {
    "id": "h-100",
    "name": "Arthas",
    "level": 1,
    "power": 10,
    "created_at": "2025-12-18T16:00:00Z"
  }
}
```

**Tipos de Eventos:**
- ‚úÖ **√âxito**: `HeroCreated`, `HeroUpdated`, `HeroDeleted`
- ‚ùå **Fallo**: `HeroCreateFailed`, `HeroUpdateFailed`, `HeroDeleteFailed`

```mermaid
%%{
  init: {
    'theme': 'dark',
    'themeVariables': {
      'primaryColor': '#1f2937',
      'edgeLabelBackground':'#1f2937',
      'tertiaryColor': '#111827',
      'mainBkg': '#1f2937',
      'nodeBorder': '#8b5cf6',
      'lineColor': '#3b82f6',
      'textColor': '#f3f4f6'
    }
  }
}%%
sequenceDiagram
    participant User
    participant API as üåê API (HTTP)
    participant Srv as üß† Service
    participant DB as üíæ MemoryDB
    participant Bus as üì® KafkaBus
    participant Worker as üéß Consumer
    participant DLQ as üóëÔ∏è DLQ Topic

    Note over User, DLQ: Flujo COMMAND (Crear - √âxito)
    User->>API: POST /heroes {"name":"Arthas"}
    API->>Srv: Create(Cmd)
    
    Srv->>DB: Save(Hero)
    DB-->>Srv: OK
    
    Srv->>Bus: Publish("HeroCreated")
    Bus->>Worker: Event "HeroCreated"
    Worker->>Worker: Process OK
    Worker->>Bus: Commit Offset
    
    Srv-->>API: nil
    API-->>User: 201 Created

    Note over User, DLQ: Flujo COMMAND (Crear - Fallo)
    User->>API: POST /heroes {"name":""}
    API->>Srv: Create(Cmd)
    Srv->>Srv: Validation Error
    Srv->>Bus: Publish("HeroCreateFailed")
    Srv-->>API: error
    API-->>User: 500 Error

    Note over User, DLQ: Consumer con DLQ
    Bus->>Worker: Event (Poison Message)
    Worker->>Worker: Process FAIL
    Worker->>DLQ: Send to DLQ
    Worker->>Bus: Commit Offset (avanza)
```

## 2. Refactorizaci√≥n y Estructura

Para mantener el c√≥digo limpio y profesional, hemos dividido el Servicio (`herosrv`) en archivos seg√∫n su responsabilidad (Vertical Slicing dentro del componente):

-   `service.go`: Definici√≥n de Dependencias (`struct`) y Factory (`New`).
-   `create.go`: L√≥gica de Escritura (**Command**).
-   `get.go`: L√≥gica de Lectura (**Query**).
-   `update.go`: L√≥gica de Actualizaci√≥n (**Command**).
-   `delete.go`: L√≥gica de Eliminaci√≥n (**Command**).
-   `list.go`: L√≥gica de Listado (**Query**).

## 3. SOLID aplicado al Microservicio

Durante todo el tutorial hemos aplicado patrones SOLID casi sin darnos cuenta. Aqu√≠ est√°n explicados en nuestro c√≥digo:

| Letra | Principio | D√≥nde se aplica | Explicaci√≥n |
| :--- | :--- | :--- | :--- |
| **S** | **SRP** (Responsabilidad √önica) | `create.go` vs `get.go` vs `update.go` | Hemos separado cada operaci√≥n CRUD en archivos distintos. Cada archivo tiene una √∫nica raz√≥n para cambiar. |
| **O** | **OCP** (Abierto/Cerrado) | `EventBus` | Agregamos Kafka SIN tocar el Dominio. Podr√≠amos agregar RabbitMQ haciendo otra implementaci√≥n sin romper el `Service`. |
| **L** | **LSP** (Sustituci√≥n de Liskov) | `MemoryRepo` | `MemoryRepo` cumple con `ports.HeroRepository` igual que lo har√≠a un `PostgresRepo`. El Servicio no sabe la diferencia. |
| **I** | **ISP** (Segregaci√≥n de Interfaces) | `HeroRepository` vs `EventBus` | Separamos las interfaces de persistencia y eventos. Un servicio no necesita implementar ambas. |
| **D** | **DIP** (Inversi√≥n de Dependencias) | `Service` depende de `ports` | El core depende de abstracciones (interfaces), no de implementaciones concretas (Kafka, Memory). |

### Integraci√≥n con Plataforma (Infraestructura)

Este microservicio es "Cloud Agnostic" pero depende de que exista una infraestructura de mensajer√≠a.
Usaremos **Platform Kafka Admin** para proveer esa infra.

1.  **Levantar Plataforma** (si no est√° corriendo):
    ```bash
    cd projects/platform-kafka-admin
    make initAll
    ```

2.  **Provisionar Recursos (Topics)**:
    ```bash
    # Topic principal
    curl -X POST -d '{"name":"hero-events-05"}' http://localhost:3000/topics
    
    # Topic DLQ (Dead Letter Queue)
    curl -X POST -d '{"name":"hero-events-05-dlq"}' http://localhost:3000/topics
    ```

3.  **Ejecutar Servicio**:
    ```bash
    cd projects/section-05-full-cycle
    make run-api
    ```

4.  **Ejecutar Consumer** (en otra terminal):
    ```bash
    make run-consumer
    ```

### üß™ Probando el Sistema Completo

#### **1. Crear un H√©roe (CREATE)**
```bash
curl -X POST -d '{"name":"Arthas"}' http://localhost:8081/heroes
```
- Respuesta:
```json
{
  "status": "created",
  "time": "2.3ms",
  "hero": {
    "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "name": "Arthas",
    "level": 1,
    "power": 10,
    "created_at": "2025-12-18T16:00:00Z"
  }
}
```
- Consumer log: `üì® CONSUMER: event_type=HeroCreated`
- **Nota**: El ID se genera autom√°ticamente usando UUID v4

#### **2. Listar H√©roes (LIST)**
```bash
curl http://localhost:8081/heroes
```
- Respuesta: `[{"id":"h-100","name":"Arthas",...}]`

#### **3. Consultar un H√©roe (READ)**
```bash
curl "http://localhost:8081/heroes?id=h-100"
```
- Respuesta: `{"id":"h-100","name":"Arthas",...}`

#### **4. Actualizar un H√©roe (UPDATE)**
```bash
curl -X PUT -d '{"name":"Arthas Menethil"}' "http://localhost:8081/heroes?id=h-100"
```
- Respuesta: `{"status":"updated"}`
- Consumer log: `üì® CONSUMER: event_type=HeroUpdated`

#### **5. Eliminar un H√©roe (DELETE)**
```bash
curl -X DELETE "http://localhost:8081/heroes?id=h-100"
```
- Respuesta: `{"status":"deleted"}`
- Consumer log: `üì® CONSUMER: event_type=HeroDeleted`

#### **6. Probar Evento de Fallo**
```bash
curl -X POST -d '{"name":""}' http://localhost:8081/heroes
```
- Respuesta: `error creando hero: hero name cannot be empty`
- Consumer log: `üì® CONSUMER: event_type=HeroCreateFailed`

#### **7. Verificar DLQ** (Dead Letter Queue)
```bash
# Enviar mensaje venenoso directamente a Kafka
docker exec -i kafka /opt/kafka/bin/kafka-console-producer.sh \
  --bootstrap-server localhost:9092 \
  --topic hero-events-05 << EOF
{"fail":true}
EOF

# El consumer lo enviar√° al DLQ y seguir√° procesando
```

## 4. Conclusi√≥n

Has construido un sistema:
1.  **CRUD Completo**: Create, Read, Update, Delete, List.
2.  **Event-Driven**: Todos los eventos (√©xito y fallo) se publican en Kafka.
3.  **Resiliente**: DLQ para mensajes venenosos, el consumer nunca se bloquea.
4.  **Desacoplado**: Cambiar Kafka por RabbitMQ es trivial.
5.  **Testable**: Puedes mockear `ports.HeroRepository`.
6.  **Escalable**: El Consumer puede correr en 10 instancias distintas.
7.  **Organizado**: Con CQS y SOLID, el c√≥digo es f√°cil de navegar.
8.  **Observable**: Eventos con `event_type` y `occurred_at` para trazabilidad completa.

¬°Felicidades! Tienes una arquitectura profesional en Go con patrones de producci√≥n.
